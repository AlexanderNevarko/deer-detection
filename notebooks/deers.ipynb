{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55df0dc-ffa2-491a-a6c2-612e7e489ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0 True\n",
      "2.18.1\n",
      "10.1\n",
      "GCC 7.3\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f36bb-be72-465d-b1d6-d023c3e98361",
   "metadata": {},
   "source": [
    "## Download original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b7709c-d8c1-4d05-b585-ae6e5e6e53aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘/mmdetection/checkpoints/vfnet.pth’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p /mmdetection/checkpoints/\n",
    "! wget -nc https://download.openmmlab.com/mmdetection/v2.0/vfnet/vfnet_x101_64x4d_fpn_mdconv_c3-c5_mstrain_2x_coco/vfnet_x101_64x4d_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-b5f6da5e.pth \\\n",
    "       -O /mmdetection/checkpoints/vfnet.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb02992-1bb7-474e-a3db-f6082ad6a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "\n",
    "# Choose to use a config and initialize the detector\n",
    "config = '/mmdetection/configs/vfnet/vfnet_x101_64x4d_fpn_mdconv_c3-c5_mstrain_2x_coco.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = '/mmdetection/checkpoints/vfnet.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44998a-650d-4eb0-bb89-cf9f637f81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the detector\n",
    "model = init_detector(config, checkpoint, device='cuda:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39c3eb-4063-41e9-83a9-dd474634c1a7",
   "metadata": {},
   "source": [
    "## Change the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56960bd8-8b06-4895-ba78-f8fdc4a30f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile(config)\n",
    "\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'CocoDataset'\n",
    "cfg.classes = ('fawn', 'reindeer')\n",
    "cfg.data_root = '/mmdetection/data/'\n",
    "#cfg.train_pipeline.insert(\n",
    "#    4,\n",
    "#    dict(\n",
    "#        type='CutOut',\n",
    "#        n_holes=(0, 4),\n",
    "#        cutout_ratio=[(0.01, 0.008), (0.005, 0.01), (0.005, 0.01), (0.01, 0.01)],\n",
    "#    )\n",
    "#)\n",
    "#cfg.train_pipeline.insert(\n",
    "#    4,\n",
    "#    dict(\n",
    "#        type='RandomAffine',\n",
    "#        n_holes=(0, 4),\n",
    "#        cutout_ratio=[(0.01, 0.008), (0.005, 0.01), (0.005, 0.01), (0.01, 0.01)],\n",
    "#    )\n",
    "#)\n",
    "\n",
    "cfg.data.samples_per_gpu = 4\n",
    "cfg.data.workers_per_gpu = 4\n",
    "\n",
    "cfg.data.test.type = 'CocoDataset'\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.ann_file = 'test/coco_annotations.json'\n",
    "cfg.data.test.img_prefix = 'test/data/'\n",
    "cfg.data.test.classes = cfg.classes\n",
    "\n",
    "cfg.data.train.type = 'CocoDataset'\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.ann_file = 'train/coco_annotations.json'\n",
    "cfg.data.train.img_prefix = 'train/data/'\n",
    "cfg.data.train.classes = cfg.classes\n",
    "\n",
    "cfg.data.val.type = 'CocoDataset'\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.ann_file = 'all_data/coco_annotations.json'\n",
    "cfg.data.val.img_prefix = 'all_data/images/'\n",
    "cfg.data.val.classes = cfg.classes\n",
    "\n",
    "\n",
    "cfg.model.bbox_head.num_classes = len(cfg.classes)\n",
    "\n",
    "# We can still use the pre-trained model\n",
    "cfg.load_from = checkpoint\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './deers_exps/'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer.lr = 0.002 / 8\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = ['bbox', ]\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 1\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 3\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = [1, ]\n",
    "\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "#print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a478d10-c0a0-478e-a00e-ae8408a5d92f",
   "metadata": {},
   "source": [
    "## Let's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26439115-0afc-45e4-ab0c-bd6b9cf52336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "('fawn', 'reindeer')\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 13:07:06,486 - mmdet - INFO - load checkpoint from local path: /mmdetection/checkpoints/vfnet.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 13:07:08,256 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.vfnet_cls.weight: copying a param with shape torch.Size([80, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([2, 256, 3, 3]).\n",
      "size mismatch for bbox_head.vfnet_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "2021-11-19 13:07:08,264 - mmdet - INFO - Start running, host: root@0751bf428dc3, work_dir: /mmdetection/notebooks/deers_exps\n",
      "2021-11-19 13:07:08,265 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2021-11-19 13:07:08,268 - mmdet - INFO - workflow: [('train', 1)], max: 24 epochs\n",
      "2021-11-19 13:07:08,269 - mmdet - INFO - Checkpoints will be saved to /mmdetection/notebooks/deers_exps by HardDiskBackend.\n",
      "[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())\n",
      "2021-11-19 13:08:03,307 - mmdet - INFO - Epoch [1][10/152]\tlr: 2.905e-05, eta: 5:33:36, time: 5.502, data_time: 0.449, memory: 15380, loss_cls: 14.1101, loss_bbox: 0.4087, loss_bbox_rf: 0.5465, loss: 15.0652\n",
      "2021-11-19 13:09:00,551 - mmdet - INFO - Epoch [1][20/152]\tlr: 3.355e-05, eta: 5:39:24, time: 5.724, data_time: 0.012, memory: 15864, loss_cls: 0.9605, loss_bbox: 0.3819, loss_bbox_rf: 0.5057, loss: 1.8481\n",
      "2021-11-19 13:09:56,380 - mmdet - INFO - Epoch [1][30/152]\tlr: 3.805e-05, eta: 5:37:51, time: 5.583, data_time: 0.013, memory: 15864, loss_cls: 1.0417, loss_bbox: 0.3927, loss_bbox_rf: 0.5235, loss: 1.9579\n",
      "2021-11-19 13:10:51,615 - mmdet - INFO - Epoch [1][40/152]\tlr: 4.255e-05, eta: 5:35:44, time: 5.524, data_time: 0.013, memory: 15864, loss_cls: 1.1157, loss_bbox: 0.3590, loss_bbox_rf: 0.4760, loss: 1.9507\n",
      "2021-11-19 13:11:46,120 - mmdet - INFO - Epoch [1][50/152]\tlr: 4.705e-05, eta: 5:33:12, time: 5.450, data_time: 0.013, memory: 15864, loss_cls: 0.9795, loss_bbox: 0.3681, loss_bbox_rf: 0.4882, loss: 1.8357\n",
      "2021-11-19 13:12:40,012 - mmdet - INFO - Epoch [1][60/152]\tlr: 5.155e-05, eta: 5:30:36, time: 5.389, data_time: 0.015, memory: 15864, loss_cls: 0.9432, loss_bbox: 0.3444, loss_bbox_rf: 0.4583, loss: 1.7460\n",
      "2021-11-19 13:13:34,654 - mmdet - INFO - Epoch [1][70/152]\tlr: 5.605e-05, eta: 5:29:08, time: 5.464, data_time: 0.015, memory: 15864, loss_cls: 0.7890, loss_bbox: 0.4020, loss_bbox_rf: 0.5308, loss: 1.7219\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import os.path as osp\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "\n",
    "\n",
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_detector(\n",
    "    cfg.model,\n",
    "    train_cfg=cfg.get('train_cfg'),\n",
    "    test_cfg=cfg.get('test_cfg'),\n",
    ")\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "print(datasets[0].CLASSES)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e7ee0-854c-40d0-a9d5-44b5d1d37de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
